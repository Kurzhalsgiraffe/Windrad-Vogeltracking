{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stereo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import copy\n",
    "import time\n",
    "bs = 5\n",
    "\n",
    "capl = cv2.VideoCapture(\"Stereo1.mp4\")\n",
    "capr = cv2.VideoCapture(\"Stereo2.mp4\")\n",
    "\n",
    "while True:\n",
    "    stereo = cv2.StereoBM_create(numDisparities=0, blockSize=bs)\n",
    "    ret, right = capr.read()\n",
    "    ret, left = capl.read()\n",
    "    imgR = cv2.cvtColor(right, cv2.COLOR_BGR2GRAY)\n",
    "    imgL = cv2.cvtColor(left, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    disparity = stereo.compute(imgL, imgR)\n",
    "    stereo = cv.normalize(disparity, None, alpha = 0, beta = 1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)\n",
    "    \n",
    "    cv2.imshow(\"R\",imgR)\n",
    "    cv2.imshow(\"L\",imgL)\n",
    "    cv2.imshow(\"stereo\", stereo)\n",
    "    \n",
    "    key = cv.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    if key == ord('x'):\n",
    "        bs+=2\n",
    "    if key == ord('y'):\n",
    "        bs-=2\n",
    "    if key == ord(\"p\"):\n",
    "        cv2.waitKey(-1)\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "capl.release()\n",
    "capr.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seitenansicht 1 Vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vs = cv2.VideoCapture(\"test2.mp4\")\n",
    "ret, frame = vs.read()\n",
    "old = None\n",
    "count = 1\n",
    "\n",
    "max_cnt_area = 700\n",
    "upper_border_height = 40\n",
    "lower_border_height = 500\n",
    "shredder_left = 430\n",
    "shredder_right = 830\n",
    "margin = 80\n",
    "\n",
    "dangerzone_left = ((margin, upper_border_height), (shredder_left,lower_border_height))\n",
    "dangerzone_right = ((shredder_right, upper_border_height), (frame.shape[1]-margin, lower_border_height))\n",
    "shredderzone = ((shredder_left, upper_border_height), (shredder_right,lower_border_height))\n",
    "\n",
    "def overlap(mid):\n",
    "    if dangerzone_right[0][0] < mid[0] < dangerzone_right[1][0] and dangerzone_right[0][1] < mid[1] < dangerzone_right[1][1]:\n",
    "        return \"Rechts\"\n",
    "    elif dangerzone_left[0][0] < mid[0] < dangerzone_left[1][0] and dangerzone_left[0][1] < mid[1] < dangerzone_left[1][1]:\n",
    "        return \"Links\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#while True: #Endlosschleife für Live-Video, hier forschleife über endliches Video\n",
    "for i in range(1,int(vs.get(cv2.CAP_PROP_FRAME_COUNT))) :\n",
    "    ret, frame = vs.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "        \n",
    "    if old is None:\n",
    "        old = gray\n",
    "        continue\n",
    "        \n",
    "    frameDelta = cv2.absdiff(old, gray)\n",
    "    thresh = cv2.threshold(frameDelta, 5, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    for c in cnts:\n",
    "        # if the contour is too big, ignore it\n",
    "        if cv2.contourArea(c) > max_cnt_area:\n",
    "            continue\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        tl = (x, y)\n",
    "        br = (x+w, y+h)\n",
    "        mid = (x+w//2,y+h//2)\n",
    "        ov = overlap(mid)\n",
    "        if ov:\n",
    "            cv2.putText(frame,ov,(20,700),cv2.FONT_HERSHEY_COMPLEX,1,(0,163,255),2)\n",
    "        cv2.circle(frame, mid, 2, (0, 0, 255), 2)\n",
    "        cv2.rectangle(frame, tl, br, (0, 255, 0), 2)\n",
    "    \n",
    "    if count%2 == 0:\n",
    "        old = gray #Setze old auf aktuelles Bild, um es im nächsten Durchlauf zu vergleichen\n",
    "        count = 1\n",
    "    count+=1\n",
    "    \n",
    "    #Label\n",
    "    cv2.rectangle(frame, dangerzone_left[0], dangerzone_left[1], (0, 255, 255), 1) #dangerzone left\n",
    "    cv2.rectangle(frame, dangerzone_right[0], dangerzone_right[1], (0, 255, 255), 1) #dangerzone right\n",
    "    cv2.rectangle(frame, shredderzone[0], shredderzone[1], (0, 0, 255), 1) #shredderzone\n",
    "    \n",
    "    #Bilder anzeigen\n",
    "    cv2.imshow(\"Thresh\", thresh)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Frame Delta\", frameDelta)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "    if key == ord(\"p\"):\n",
    "        cv2.waitKey(-1)\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "vs.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live-Kamera-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vs = cv2.VideoCapture(0)\n",
    "vs.set(3, 1920)\n",
    "vs.set(4, 1080)\n",
    "ret, frame = vs.read()\n",
    "old = None\n",
    "\n",
    "max_cnt_area = 700\n",
    "upper_border_height = 40\n",
    "lower_border_height = 700\n",
    "shredder_left = 700\n",
    "shredder_right = 1200\n",
    "margin = 80\n",
    "\n",
    "dangerzone_left = ((margin, upper_border_height), (shredder_left,lower_border_height))\n",
    "dangerzone_right = ((shredder_right, upper_border_height), (frame.shape[1]-margin, lower_border_height))\n",
    "shredderzone = ((shredder_left, upper_border_height), (shredder_right,lower_border_height))\n",
    "\n",
    "def overlap(mid):\n",
    "    if dangerzone_right[0][0] < mid[0] < dangerzone_right[1][0] and dangerzone_right[0][1] < mid[1] < dangerzone_right[1][1]:\n",
    "        return \"Rechts\"\n",
    "    elif dangerzone_left[0][0] < mid[0] < dangerzone_left[1][0] and dangerzone_left[0][1] < mid[1] < dangerzone_left[1][1]:\n",
    "        return \"Links\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "while True: #Endlosschleife für Live-Video, hier forschleife über endliches Video\n",
    "    ret, frame = vs.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "        \n",
    "    if old is None:\n",
    "        old = gray\n",
    "        continue\n",
    "        \n",
    "    frameDelta = cv2.absdiff(old, gray)\n",
    "    thresh = cv2.threshold(frameDelta, 5, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    for c in cnts:\n",
    "        # if the contour is too big, ignore it\n",
    "        if cv2.contourArea(c) > max_cnt_area:\n",
    "            continue\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        tl = (x, y)\n",
    "        br = (x+w, y+h)\n",
    "        mid = (x+w//2,y+h//2)\n",
    "        ov = overlap(mid)\n",
    "        if ov:\n",
    "            cv2.putText(frame,ov,(20,700),cv2.FONT_HERSHEY_COMPLEX,1,(0,163,255),2)\n",
    "        cv2.circle(frame, mid, 2, (0, 0, 255), 2)\n",
    "        cv2.rectangle(frame, tl, br, (0, 255, 0), 2)\n",
    "    \n",
    "    old = gray #Setze old auf aktuelles Bild, um es im nächsten Durchlauf zu vergleichen\n",
    "    \n",
    "    #Label\n",
    "    cv2.rectangle(frame, dangerzone_left[0], dangerzone_left[1], (0, 255, 255), 1) #dangerzone left\n",
    "    cv2.rectangle(frame, dangerzone_right[0], dangerzone_right[1], (0, 255, 255), 1) #dangerzone right\n",
    "    cv2.rectangle(frame, shredderzone[0], shredderzone[1], (0, 0, 255), 1) #shredderzone\n",
    "    \n",
    "    #Bilder anzeigen\n",
    "    cv2.imshow(\"Thresh\", thresh)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Frame Delta\", frameDelta)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "    if key == ord(\"p\"):\n",
    "        cv2.waitKey(-1)\n",
    "cv2.destroyAllWindows()\n",
    "vs.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 120° Methode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------ Imports ------------------------#\n",
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "#------------------------ Videos festlegen ------------------------#\n",
    "Video = 4\n",
    "Videos = {\n",
    "            1:[\"Simulation1\",(917,518),170,20],\n",
    "            2:[\"3D/Simulation1_Front\",(962,548),200,20],\n",
    "            3:[\"Kosmos1\",(790,400),450,50],\n",
    "            4:[\"Kosmos2\",(790,400),450,50]\n",
    "         }\n",
    "\n",
    "#------------------------ Videoparameter festlegen ------------------------#\n",
    "vs = cv2.VideoCapture(Videos[Video][0]+\".mp4\")\n",
    "center = Videos[Video][1]\n",
    "rotor_radius = Videos[Video][2]\n",
    "hub_circle_radius = Videos[Video][3]\n",
    "\n",
    "#------------------------ Algorithmus ------------------------#\n",
    "old = None \n",
    "for i in range(0,int(vs.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "    ret, frame = vs.read()                                   # Bild aus Video einlesen\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)           # Bild zu grau konvertieren\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)               # Bild blurren\n",
    "        \n",
    "    if old is None:                                          # Erstes Bild initialisieren\n",
    "        old = gray                                           #\n",
    "        continue                                             #\n",
    "        \n",
    "    frameDelta = cv2.absdiff(old, gray)                                                   # Differenz (Delta) zwischen altem und neuem Bild berechnen\n",
    "    thresh = cv2.threshold(frameDelta, 5, 255, cv2.THRESH_BINARY)[1]                      # Delta threshholde\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)                                       #\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)    # Alle zusammenhängenden Konturen erkennen\n",
    "    cnts = imutils.grab_contours(cnts)                                                    #\n",
    "    \n",
    "    for c in cnts:                                                       # Für jede Kontur...\n",
    "        line_image = np.zeros(frame.shape[:-1])                          # Neues leeres Bild mit gleicher Größe erstellen (Für spätere Berechnungen)\n",
    "    \n",
    "        distances = [np.linalg.norm(center-i[0]) for i in c]             # Distanzen aller Punkte der Kontur zum Center berechnen\n",
    "        point = c[np.argsort(distances)[-1]][0]                          # Punkt mit größter Distanz ermitteln\n",
    "        distance = np.sort(distances)[-1]                                # Distanz dieses Punktes ermitteln\n",
    "    \n",
    "        z = (complex(point[0],point[1]) - complex(center[0],center[1])) * (-0.4999999999999998-0.8660254037844387j) + complex(center[0],center[1])     # Punkt der um 120° angewinkelte Linie berechnen\n",
    "        angled_point_coords = np.int32([z.real,z.imag])                                                                                                #\n",
    "        \n",
    "        cv2.line(line_image, angled_point_coords, center, (255,255,255), 25)              # Angewinkelte Linie auf leeres Bild einzeichnen\n",
    "        #cv2.line(frame, angled_point_coords, center, (255,255,255), 25)                  # Diese Linie anzeigen (optional)\n",
    "        \n",
    "        #cv2.putText(frame,str(distance),point,cv2.FONT_HERSHEY_COMPLEX,1,(0,163,255),2)  # Distanz anzeigen (optional)\n",
    "        \n",
    "        if (distance < rotor_radius and np.sum(np.int32(line_image) & thresh) > 100000) or distance < hub_circle_radius:       # Wenn Punkt zwischen im Rotorbereich ist, und Angewinkelte Linie \n",
    "                cv2.line(frame, point, center, (0,0,255), 2)                                                                 # mehr als 1000 Pixel von anderen Konturen überdeckt, gehört Kontur zum Rotor\n",
    "        else:\n",
    "            cv2.line(frame, point, center, (255,0,0), 2)                                                                     # Andernfalls Vogel -> Blaue Linie + Kreis\n",
    "            cv2.circle(frame, point, 10, (255,0,0), 2)\n",
    "    \n",
    "    old = gray   #Setze old auf aktuelles Bild, um es im nächsten Durchlauf zu vergleichen\n",
    "    \n",
    "#------------------------ Anzeigen ------------------------#\n",
    "\n",
    "    cv2.circle(frame, center, rotor_radius, (0, 255, 255), 2)          # Kreise einzeichnen\n",
    "    cv2.circle(frame, center, hub_circle_radius, (0, 0, 0), 2)         #\n",
    "    cv2.circle(frame, center, 2, (255, 0, 255), 2)                     #\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    #cv2.imshow(\"line\", line_image)\n",
    "    cv2.imshow(\"Thresh\", thresh)\n",
    "    #cv2.imshow(\"Frame Delta\", frameDelta)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "    if key == ord(\"p\"):\n",
    "        cv2.waitKey(-1)\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "vs.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windrad maskieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------ Imports ------------------------#\n",
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "#------------------------ Videos festlegen ------------------------#\n",
    "Video = 1\n",
    "Videos = {\n",
    "            1:[\"Simulation1\",(917,518),170,20,13],\n",
    "            2:[\"3D/Simulation1_Front\",(962,548),200,20,48],\n",
    "            3:[\"Kosmos1\",(790,400),450,50,0],\n",
    "            4:[\"Kosmos2\",(790,400),450,50,0]\n",
    "         }\n",
    "\n",
    "#------------------------ Videoparameter festlegen ------------------------#\n",
    "vs = cv2.VideoCapture(Videos[Video][0]+\".mp4\")\n",
    "center = Videos[Video][1]\n",
    "rotor_radius = Videos[Video][2]\n",
    "hub_circle_radius = Videos[Video][3]\n",
    "img_count = Videos[Video][4]\n",
    "\n",
    "#------------------------ Kreis fürs Rotor ausblenden ------------------------#\n",
    "frames_per_rotation = 180\n",
    "theta = np.linspace(0, -2*np.pi, num=frames_per_rotation) #180 Werte zwischen 0 und 2*pi\n",
    "x = rotor_radius*np.sin(theta) # x-Koordinaten nach Einheitskreis\n",
    "y = rotor_radius*np.cos(theta) # y-Koordinaten nach Einheitskreis\n",
    "rotor_positions = [(int(x[i])+center[0],int(y[i])+center[1]) for i in range(frames_per_rotation)]\n",
    "\n",
    "#------------------------ Variablen ------------------------#\n",
    "old = None\n",
    "\n",
    "#------------------------ Algorithmus ------------------------#\n",
    "for i in range(0,int(vs.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "    img_count = (img_count+1)%frames_per_rotation            # Counter hochzählen (maximal 180)\n",
    "    ret, frame = vs.read()                                   # Bild aus Video einlesen\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)           # Bild zu grau konvertieren\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)               # Bild blurren\n",
    "        \n",
    "    if old is None:                                          # Erstes Bild initialisieren\n",
    "        old = gray                                           #\n",
    "        continue                                             #\n",
    "    \n",
    "    line_image = np.zeros(frame.shape[:-1])                  # Neues leeres Bild mit gleicher Größe erstellen (Für spätere Berechnungen)\n",
    "    for i in range(0,frames_per_rotation,frames_per_rotation//3):\n",
    "        pos = rotor_positions[(img_count+i)%frames_per_rotation]\n",
    "        cv2.line(line_image, pos, center, (255,255,255), 65)              # Angewinkelte Linie auf leeres Bild einzeichnen\n",
    "        #cv2.line(frame, pos, center, (255,255,255), 65)                  # Diese Linie auch auf frame anzeigen (optional)\n",
    "    \n",
    "    \n",
    "    frameDelta = cv2.absdiff(old, gray)                                                   # Differenz (Delta) zwischen altem und neuem Bild berechnen\n",
    "    thresh = cv2.threshold(frameDelta, 10, 255, cv2.THRESH_BINARY)[1]                      # Delta threshholde\n",
    "    thresh = cv2.dilate(thresh, None, iterations=4)                                       #\n",
    "    thresh = thresh - np.uint8(line_image)\n",
    "    thresh = cv2.threshold(thresh, 120, 255, cv2.THRESH_BINARY)[1]\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)    # Alle zusammenhängenden Konturen erkennen\n",
    "    cnts = imutils.grab_contours(cnts)                                                    #\n",
    "    \n",
    "    for c in cnts:\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        tl = (x, y)\n",
    "        br = (x+w, y+h)\n",
    "        mid = (x+w//2,y+h//2)\n",
    "        cv2.circle(frame, mid, 10, (255,0,0), 2)\n",
    "    \n",
    "    old = gray   #Setze old auf aktuelles Bild, um es im nächsten Durchlauf zu vergleichen\n",
    "    \n",
    "#------------------------ Anzeigen ------------------------#\n",
    "\n",
    "    cv2.circle(frame, center, rotor_radius, (0, 255, 255), 2)          # Kreise einzeichnen\n",
    "    cv2.circle(frame, center, hub_circle_radius, (0, 0, 0), 2)         #\n",
    "    cv2.circle(frame, center, 2, (255, 0, 255), 2)                     #\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"line\", line_image)\n",
    "    cv2.imshow(\"Thresh\", thresh)\n",
    "    #cv2.imshow(\"Frame Delta\", frameDelta)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "    if key == ord(\"p\"):\n",
    "        time.sleep(5)\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "vs.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D-Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------ Imports ------------------------#\n",
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "#------------------------ Videos festlegen ------------------------#\n",
    "Video = 3\n",
    "Videos = {\n",
    "            1:[\"Simulation1\",(917,518),170,20,13],\n",
    "            2:[\"3D/Simulation1_Front\",(962,548),200,20,48],\n",
    "            3:[\"3D/Simulation2_Front\",(962,548),200,20,48],\n",
    "            4:[\"Kosmos1\",(790,400),450,50,0],\n",
    "            5:[\"Kosmos2\",(790,400),450,50,0]\n",
    "         }\n",
    "\n",
    "#------------------------ Videoparameter festlegen ------------------------#\n",
    "vs = cv2.VideoCapture(Videos[Video][0]+\".mp4\")\n",
    "center = Videos[Video][1]\n",
    "rotor_radius = Videos[Video][2]\n",
    "hub_circle_radius = Videos[Video][3]\n",
    "img_count = Videos[Video][4]\n",
    "\n",
    "#------------------------ Kreis fürs Rotor ausblenden ------------------------#\n",
    "frames_per_rotation = 180\n",
    "theta = np.linspace(0, -2*np.pi, num=frames_per_rotation) #180 Werte zwischen 0 und 2*pi\n",
    "x = rotor_radius*np.sin(theta) # x-Koordinaten nach Einheitskreis\n",
    "y = rotor_radius*np.cos(theta) # y-Koordinaten nach Einheitskreis\n",
    "rotor_positions = [(int(x[i])+center[0],int(y[i])+center[1]) for i in range(frames_per_rotation)]\n",
    "\n",
    "#------------------------ Variablen ------------------------#\n",
    "frame_old = None\n",
    "birds = {0:[np.array((0,0))]}\n",
    "#------------------------ Algorithmus ------------------------#\n",
    "for i in range(0,int(vs.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "    img_count = (img_count+1)%frames_per_rotation            # Counter hochzählen (maximal 180)\n",
    "    ret, frame = vs.read()                                   # Bild aus Video einlesen\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)           # Bild zu grau konvertieren\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)               # Bild blurren\n",
    "        \n",
    "    if frame_old is None:                                          # Erstes Bild initialisieren\n",
    "        frame_old = gray                                           #\n",
    "        continue                                             #\n",
    "    \n",
    "    line_image = np.zeros(frame.shape[:-1])                  # Neues leeres Bild mit gleicher Größe erstellen (Für spätere Berechnungen)\n",
    "    for i in range(0,frames_per_rotation,frames_per_rotation//3):\n",
    "        pos = rotor_positions[(img_count+i)%frames_per_rotation]\n",
    "        cv2.line(line_image, pos, center, (255,255,255), 65)              # Angewinkelte Linie auf leeres Bild einzeichnen\n",
    "        #cv2.line(frame, pos, center, (255,255,255), 65)                  # Diese Linie auch auf frame anzeigen (optional)\n",
    "    \n",
    "    \n",
    "    frameDelta = cv2.absdiff(frame_old, gray)                                                   # Differenz (Delta) zwischen altem und neuem Bild berechnen\n",
    "    thresh = cv2.threshold(frameDelta, 10, 255, cv2.THRESH_BINARY)[1]                      # Delta threshholde\n",
    "    thresh = cv2.dilate(thresh, None, iterations=4)                                       #\n",
    "    thresh = thresh - np.uint8(line_image)\n",
    "    thresh = cv2.threshold(thresh, 120, 255, cv2.THRESH_BINARY)[1]\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)    # Alle zusammenhängenden Konturen erkennen\n",
    "    cnts = imutils.grab_contours(cnts)                                                    #\n",
    "    \n",
    "    current_mids = []                                      # Neue leere Liste für die Mittelpunkte\n",
    "    for c in cnts:\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        mid = np.array((x+w//2,y+h//2))\n",
    "        cv2.circle(frame, mid, 50, (255,0,0), 2)\n",
    "        cv2.circle(frame, mid, 5, (255,255,0), 2)\n",
    "        \n",
    "        current_mids.append(mid)                          # Alle Konturmittelpunkte werden der neuen Liste hinzugefügt\n",
    "    \n",
    "    for i in current_mids:\n",
    "        d=[np.linalg.norm(i-j) for j in old_mids if list(j)!=list(i)] # Distanzen von Punkt i aus dem aktuellen Frame zu allen anderen Punkten aus dem letzten Frame\n",
    "        cv2.putText(frame,str(d),i,cv2.FONT_HERSHEY_COMPLEX,1,(0,163,255),2)\n",
    "        # Ab hier brainfuck:\n",
    "        # Punkt i muss dem Vogel zugeordnet werden, der min(d) hat, oder neuer Vogel muss erstellt werden.\n",
    "        if d:\n",
    "            if min(d) > 100:                       # Wenn der Mindestabstand des neuen Punkt zu allen alten Punkten über 100 ist, wird ein neuer Vogel angelegt\n",
    "                birds[max(birds.keys())+1] = [i]\n",
    "            else:                                                        # Ansonsten muss der die aktuelle Koordinate i einem bestehenden Vogel zugeordnet werden\n",
    "                X = [birds[j][-1] for j in birds]\n",
    "                d2=[np.linalg.norm(x-i) for x in X]\n",
    "                mini = np.argsort(d2)[0]\n",
    "                if mini < 100:\n",
    "                    birds[mini].append(i)\n",
    "                  \n",
    "    \n",
    "    frame_old = gray   #Setze old auf aktuelles Bild, um es im nächsten Durchlauf zu vergleichen\n",
    "    old_mids = current_mids\n",
    "    \n",
    "    colors = [[48, 99, 225],[107, 250, 115],[103, 237, 251],[250, 166, 109],[173, 57, 170],[53, 41, 163],[187, 204, 53],[114, 225, 165],[251, 122, 78],[173, 62, 99]]\n",
    "    for i in range(len(birds)):\n",
    "        cv2.polylines(frame, [np.array(birds[i][1:])], 0, colors[i%10], 3)\n",
    "\n",
    "#------------------------ Anzeigen ------------------------#\n",
    "\n",
    "    cv2.circle(frame, center, rotor_radius, (0, 255, 255), 2)          # Kreise einzeichnen\n",
    "    cv2.circle(frame, center, hub_circle_radius, (0, 0, 0), 2)         #\n",
    "    cv2.circle(frame, center, 2, (255, 0, 255), 2)                     #\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    #cv2.imshow(\"line\", line_image)\n",
    "    #cv2.imshow(\"Thresh\", thresh)\n",
    "    #cv2.imshow(\"Frame Delta\", frameDelta)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "    if key == ord(\"p\"):\n",
    "        cv2.waitKey(-1)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "vs.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
