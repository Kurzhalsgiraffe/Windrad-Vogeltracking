{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bewegte Kamera im Stereotest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4-dev) D:/a/opencv-python/opencv-python/opencv/modules/highgui/src/precomp.hpp:155: error: (-215:Assertion failed) src_depth != CV_16F && src_depth != CV_32S in function 'convertToShow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3928/165742832.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mstereo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisparity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNORM_MINMAX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCV_32F\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"R\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"L\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimgL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"stereo\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstereo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4-dev) D:/a/opencv-python/opencv-python/opencv/modules/highgui/src/precomp.hpp:155: error: (-215:Assertion failed) src_depth != CV_16F && src_depth != CV_32S in function 'convertToShow'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import copy\n",
    "import time\n",
    "bs = 15\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "ret, old = cap.read()\n",
    "\n",
    "while True:\n",
    "    stereo = cv.StereoBM_create(numDisparities=0, blockSize=bs)\n",
    "    ret, new = cap.read()\n",
    "    imgR =cv.cvtColor(new, cv.COLOR_BGR2GRAY)\n",
    "    imgL =cv.cvtColor(old, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    disparity = stereo.compute(imgL, imgR)\n",
    "    stereo = cv.normalize(disparity, None, alpha = 0, beta = 1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)\n",
    "    \n",
    "    cv.imshow(\"R\",imgR)\n",
    "    cv.imshow(\"L\",imgL)\n",
    "    cv.imshow(\"stereo\", stereo)\n",
    "    \n",
    "    key = cv.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    if key == ord('x'):\n",
    "        bs+=2\n",
    "    if key == ord('y'):\n",
    "        bs-=2\n",
    "    if key == ord('p'):\n",
    "        print(bs)\n",
    "    old = new\n",
    "    time.sleep(0.2)\n",
    "        \n",
    "cv.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stereo auf Turm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\stereobm.cpp:1190: error: (-211:One of the arguments' values is out of range) SADWindowSize must be odd, be within 5..255 and be not larger than image width or height in function 'cv::StereoBMImpl::compute'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11904/2073507090.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mimgL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mdisparity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstereo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mstereo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisparity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNORM_MINMAX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCV_32F\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\stereobm.cpp:1190: error: (-211:One of the arguments' values is out of range) SADWindowSize must be odd, be within 5..255 and be not larger than image width or height in function 'cv::StereoBMImpl::compute'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import copy\n",
    "import time\n",
    "bs = 5\n",
    "\n",
    "capl = cv.VideoCapture(\"Stereo/Stereo_Turm (1).mp4\")\n",
    "capr = cv.VideoCapture(\"Stereo/Stereo_Turm (2).mp4\")\n",
    "\n",
    "while True:\n",
    "    stereo = cv.StereoBM_create(numDisparities=0, blockSize=bs)\n",
    "    ret, right = capr.read()\n",
    "    ret, left = capl.read()\n",
    "    imgR = cv.cvtColor(right, cv.COLOR_BGR2GRAY)\n",
    "    imgL = cv.cvtColor(left, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    disparity = stereo.compute(imgL, imgR)\n",
    "    stereo = cv.normalize(disparity, None, alpha = 0, beta = 1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)\n",
    "    \n",
    "    cv.imshow(\"R\",imgR)\n",
    "    cv.imshow(\"L\",imgL)\n",
    "    cv.imshow(\"stereo\", stereo)\n",
    "    \n",
    "    key = cv.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    if key == ord('x'):\n",
    "        bs+=2\n",
    "    if key == ord('y'):\n",
    "        bs-=2\n",
    "    if key == ord('p'):\n",
    "        print(bs)\n",
    "        \n",
    "cv.destroyAllWindows()\n",
    "capl.release()\n",
    "capr.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seitenansicht 1 Vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vs = cv2.VideoCapture(\"test2.mp4\")\n",
    "ret, frame = vs.read()\n",
    "old = None\n",
    "count = 1\n",
    "\n",
    "max_cnt_area = 700\n",
    "upper_border_height = 40\n",
    "lower_border_height = 500\n",
    "shredder_left = 430\n",
    "shredder_right = 830\n",
    "margin = 80\n",
    "\n",
    "dangerzone_left = ((margin, upper_border_height), (shredder_left,lower_border_height))\n",
    "dangerzone_right = ((shredder_right, upper_border_height), (frame.shape[1]-margin, lower_border_height))\n",
    "shredderzone = ((shredder_left, upper_border_height), (shredder_right,lower_border_height))\n",
    "\n",
    "def overlap(mid):\n",
    "    if dangerzone_right[0][0] < mid[0] < dangerzone_right[1][0] and dangerzone_right[0][1] < mid[1] < dangerzone_right[1][1]:\n",
    "        return \"Rechts\"\n",
    "    elif dangerzone_left[0][0] < mid[0] < dangerzone_left[1][0] and dangerzone_left[0][1] < mid[1] < dangerzone_left[1][1]:\n",
    "        return \"Links\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#while True: #Endlosschleife für Live-Video, hier forschleife über endliches Video\n",
    "for i in range(1,int(vs.get(cv2.CAP_PROP_FRAME_COUNT))) :\n",
    "    ret, frame = vs.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "        \n",
    "    if old is None:\n",
    "        old = gray\n",
    "        continue\n",
    "        \n",
    "    frameDelta = cv2.absdiff(old, gray)\n",
    "    thresh = cv2.threshold(frameDelta, 5, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    for c in cnts:\n",
    "        # if the contour is too big, ignore it\n",
    "        if cv2.contourArea(c) > max_cnt_area:\n",
    "            continue\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        tl = (x, y)\n",
    "        br = (x+w, y+h)\n",
    "        mid = (x+w//2,y+h//2)\n",
    "        ov = overlap(mid)\n",
    "        if ov:\n",
    "            cv2.putText(frame,ov,(20,700),cv2.FONT_HERSHEY_COMPLEX,1,(0,163,255),2)\n",
    "        cv2.circle(frame, mid, 2, (0, 0, 255), 2)\n",
    "        cv2.rectangle(frame, tl, br, (0, 255, 0), 2)\n",
    "    \n",
    "    if count%2 == 0:\n",
    "        old = gray #Setze old auf aktuelles Bild, um es im nächsten Durchlauf zu vergleichen\n",
    "        count = 1\n",
    "    count+=1\n",
    "    \n",
    "    #Label\n",
    "    cv2.rectangle(frame, dangerzone_left[0], dangerzone_left[1], (0, 255, 255), 1) #dangerzone left\n",
    "    cv2.rectangle(frame, dangerzone_right[0], dangerzone_right[1], (0, 255, 255), 1) #dangerzone right\n",
    "    cv2.rectangle(frame, shredderzone[0], shredderzone[1], (0, 0, 255), 1) #shredderzone\n",
    "    \n",
    "    #Bilder anzeigen\n",
    "    cv2.imshow(\"Thresh\", thresh)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Frame Delta\", frameDelta)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "vs.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seitenansicht alle Vids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "for i in range(1,10):\n",
    "    vs = cv2.VideoCapture(\"Seitentest/Seite (\"+str(i)+\").mp4\")    \n",
    "    ret, frame = vs.read()\n",
    "    old = None\n",
    "    oldpos = 0\n",
    "\n",
    "    max_cnt_area = 800\n",
    "    upper_border_height = 40\n",
    "    lower_border_height = 500\n",
    "    shredder_left = 430\n",
    "    shredder_right = 830\n",
    "    margin = 80\n",
    "\n",
    "    dangerzone_left = ((margin, upper_border_height), (shredder_left,lower_border_height))\n",
    "    dangerzone_right = ((shredder_right, upper_border_height), (frame.shape[1]-margin, lower_border_height))\n",
    "    shredderzone = ((shredder_left, upper_border_height), (shredder_right,lower_border_height))\n",
    "\n",
    "    def overlap(mid):\n",
    "        if dangerzone_right[0][0] < mid[0] < dangerzone_right[1][0] and dangerzone_right[0][1] < mid[1] < dangerzone_right[1][1]:\n",
    "            return \"Rechts\"\n",
    "        elif dangerzone_left[0][0] < mid[0] < dangerzone_left[1][0] and dangerzone_left[0][1] < mid[1] < dangerzone_left[1][1]:\n",
    "            return \"Links\"\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    #while True: #Endlosschleife für Live-Video, hier forschleife über endliches Video\n",
    "    for i in range(1,int(vs.get(cv2.CAP_PROP_FRAME_COUNT))) :\n",
    "        ret, frame = vs.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "        if old is None:\n",
    "            old = gray\n",
    "            continue\n",
    "\n",
    "        frameDelta = cv2.absdiff(old, gray)\n",
    "        thresh = cv2.threshold(frameDelta, 5, 255, cv2.THRESH_BINARY)[1]\n",
    "        thresh = cv2.dilate(thresh, None, iterations=1)\n",
    "        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "            cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        for c in cnts:\n",
    "            # if the contour is too big, ignore it\n",
    "            if cv2.contourArea(c) > max_cnt_area:\n",
    "                continue\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            tl = (x, y)\n",
    "            br = (x+w, y+h)\n",
    "            mid = (x+w//2,y+h//2)\n",
    "            ov = overlap(mid)\n",
    "            if ov:\n",
    "                cv2.putText(frame,ov,(20,700),cv2.FONT_HERSHEY_COMPLEX,1,(0,163,255),2)\n",
    "            cv2.circle(frame, mid, 2, (0, 0, 255), 2)\n",
    "            cv2.rectangle(frame, tl, br, (0, 255, 0), 2)\n",
    "\n",
    "        old = gray #Setze old auf aktuelles Bild, um es im nächsten Durchlauf zu vergleichen\n",
    "\n",
    "        #Label\n",
    "        cv2.rectangle(frame, dangerzone_left[0], dangerzone_left[1], (0, 255, 255), 1) #dangerzone left\n",
    "        cv2.rectangle(frame, dangerzone_right[0], dangerzone_right[1], (0, 255, 255), 1) #dangerzone right\n",
    "        cv2.rectangle(frame, shredderzone[0], shredderzone[1], (0, 0, 255), 1) #shredderzone\n",
    "\n",
    "        #Bilder anzeigen\n",
    "        cv2.imshow(\"Thresh\", thresh)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        cv2.imshow(\"Frame Delta\", frameDelta)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    vs.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live-Kamera-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vs = cv2.VideoCapture(0)\n",
    "vs.set(3, 1920)\n",
    "vs.set(4, 1080)\n",
    "ret, frame = vs.read()\n",
    "old = None\n",
    "\n",
    "max_cnt_area = 700\n",
    "upper_border_height = 40\n",
    "lower_border_height = 700\n",
    "shredder_left = 700\n",
    "shredder_right = 1200\n",
    "margin = 80\n",
    "\n",
    "dangerzone_left = ((margin, upper_border_height), (shredder_left,lower_border_height))\n",
    "dangerzone_right = ((shredder_right, upper_border_height), (frame.shape[1]-margin, lower_border_height))\n",
    "shredderzone = ((shredder_left, upper_border_height), (shredder_right,lower_border_height))\n",
    "\n",
    "def overlap(mid):\n",
    "    if dangerzone_right[0][0] < mid[0] < dangerzone_right[1][0] and dangerzone_right[0][1] < mid[1] < dangerzone_right[1][1]:\n",
    "        return \"Rechts\"\n",
    "    elif dangerzone_left[0][0] < mid[0] < dangerzone_left[1][0] and dangerzone_left[0][1] < mid[1] < dangerzone_left[1][1]:\n",
    "        return \"Links\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "while True: #Endlosschleife für Live-Video, hier forschleife über endliches Video\n",
    "    ret, frame = vs.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "        \n",
    "    if old is None:\n",
    "        old = gray\n",
    "        continue\n",
    "        \n",
    "    frameDelta = cv2.absdiff(old, gray)\n",
    "    thresh = cv2.threshold(frameDelta, 5, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    for c in cnts:\n",
    "        # if the contour is too big, ignore it\n",
    "        if cv2.contourArea(c) > max_cnt_area:\n",
    "            continue\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        tl = (x, y)\n",
    "        br = (x+w, y+h)\n",
    "        mid = (x+w//2,y+h//2)\n",
    "        ov = overlap(mid)\n",
    "        if ov:\n",
    "            cv2.putText(frame,ov,(20,700),cv2.FONT_HERSHEY_COMPLEX,1,(0,163,255),2)\n",
    "        cv2.circle(frame, mid, 2, (0, 0, 255), 2)\n",
    "        cv2.rectangle(frame, tl, br, (0, 255, 0), 2)\n",
    "    \n",
    "    old = gray #Setze old auf aktuelles Bild, um es im nächsten Durchlauf zu vergleichen\n",
    "    \n",
    "    #Label\n",
    "    cv2.rectangle(frame, dangerzone_left[0], dangerzone_left[1], (0, 255, 255), 1) #dangerzone left\n",
    "    cv2.rectangle(frame, dangerzone_right[0], dangerzone_right[1], (0, 255, 255), 1) #dangerzone right\n",
    "    cv2.rectangle(frame, shredderzone[0], shredderzone[1], (0, 0, 255), 1) #shredderzone\n",
    "    \n",
    "    #Bilder anzeigen\n",
    "    cv2.imshow(\"Thresh\", thresh)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Frame Delta\", frameDelta)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "vs.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotortracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Bild wird mit vorherigem Bild verglichen -> Unterschiede = Bewegung. Differenzbild wird durch threshhold weiterverarbeitet.\n",
    "2. Konturen werden ermittelt.\n",
    "3. Für jede Kontur wird der Punkt mit der größten euklidischen DIstanz zum Mittelpunkt ermittelt.\n",
    "4. Durch Imaginäre Zahl wird für jeden dieser Punkte der um 120° gedrehte Punkt gesucht.\n",
    "5. Zu diesem Punkt wird eine dickere Linie erstellt.\n",
    "6. Wenn diese Linie zu viele Pixel der Konturen-Layer überschneidet, wird angenommen, dass es sich um eine Windradkontur handelt.\n",
    "\n",
    "(Punkt 5 sollte überarbeitet werden, da immer mit Mittelpunkt überschnitten wird) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "vs = cv2.VideoCapture(\"Frontansicht.mp4\")\n",
    "vs.set(3, 1920)\n",
    "vs.set(4, 1080)\n",
    "ret, frame = vs.read()\n",
    "old = None\n",
    "center = np.array((632,203))\n",
    "line_image = np.zeros(frame.shape)\n",
    "\n",
    "for i in range(1,int(vs.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "    ret, frame = vs.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "        \n",
    "    if old is None:\n",
    "        old = gray\n",
    "        continue\n",
    "        \n",
    "    frameDelta = cv2.absdiff(old, gray)\n",
    "    thresh = cv2.threshold(frameDelta, 5, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    \n",
    "    for c in cnts:\n",
    "        line_image = np.zeros(frame.shape[:-1])\n",
    "        \n",
    "        #Koordinaten des am weitesten von center entfernten Punkts einer Kontur\n",
    "        distances = [np.linalg.norm(center-i[0]) for i in c]\n",
    "        point = c[np.argsort(distances)[-1]][0]\n",
    "        \n",
    "        #Angewinkelte Linie berechnen\n",
    "        z = (complex(point[0],point[1]) - complex(center[0],center[1])) * (-0.4999999999999998-0.8660254037844387j) + complex(center[0],center[1])\n",
    "        angled_point_coords = np.int32([z.real,z.imag])\n",
    "        \n",
    "        cv2.line(line_image, angled_point_coords, center, (255,255,255), 15)\n",
    "        cv2.line(frame, angled_point_coords, center, (255,255,255), 15)\n",
    "        \n",
    "        if np.sum(np.int32(line_image) & thresh) > 50000:\n",
    "            cv2.line(frame, point, center, (0,0,255), 2)\n",
    "        else:\n",
    "            cv2.line(frame, point, center, (255,0,0), 2)\n",
    "\n",
    "    cv2.circle(frame, center, 2, (255, 0, 255), 2)\n",
    "    old = gray #Setze old auf aktuelles Bild, um es im nächsten Durchlauf zu vergleichen\n",
    "\n",
    "    #Bilder anzeigen\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    #cv2.imshow(\"line\", line_image)\n",
    "    #cv2.imshow(\"Thresh\", thresh)\n",
    "    #cv2.imshow(\"Frame Delta\", frameDelta)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "    if key == ord('p'):\n",
    "        time.sleep(5)\n",
    "cv2.destroyAllWindows()\n",
    "vs.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.9 s ± 60.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
